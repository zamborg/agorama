{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agorama.state_agent.state_agent import BasePerceptionAgent, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import acompletion\n",
    "from pydantic import BaseModel\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionParameter(BaseModel):\n",
    "    type: str # the type of the parameter\n",
    "    description: str # a description of what the parameter is\n",
    "    required: bool # whether the parameter is required\n",
    "\n",
    "class ToolClass(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    parameters: Dict[str, FunctionParameter]\n",
    "\n",
    "\n",
    "    def payload(self):\n",
    "        required_parameters = [param_name for param_name, param in self.parameters.items() if param.required]\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": self.description,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        param_name: {\n",
    "                            \"type\": param.type,\n",
    "                            \"description\": param.description\n",
    "                        }\n",
    "                        for param_name, param in self.parameters.items()\n",
    "                    },\n",
    "                    \"required\": required_parameters\n",
    "                }\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import Field\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class Item(BaseModel):\n",
    "    \"\"\"\n",
    "    A base class for all items in the game.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    quantity: int\n",
    "    size: int\n",
    "    functionality: str # a description of what the item can do\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name} (x{self.quantity})\\n\" \\\n",
    "               f\"Description: {self.description}\\n\" \\\n",
    "               f\"Size: {self.size}\\n\" \\\n",
    "               f\"Use: {self.functionality}\"\n",
    "    \n",
    "\n",
    "class Inventory(BaseModel):\n",
    "    items: List[Item]\n",
    "    max_capacity: int\n",
    "    remaining_capacity: Optional[int] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.remaining_capacity = self.max_capacity - self._calculate_capacity()\n",
    "\n",
    "    def _calculate_capacity(self):\n",
    "        return sum(item.size for item in self.items)\n",
    "\n",
    "    def update_inventory(self, items: List[Item]):\n",
    "        self.items = items\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        if not self.items:\n",
    "            return \"Inventory is empty\\nRemaining capacity: \" + str(self.max_capacity)\n",
    "        inventory_str = \"Inventory Contents:\\n\"\n",
    "        inventory_str += \"=\" * 20 + \"\\n\"\n",
    "        for item in self.items:\n",
    "            inventory_str += str(item) + \"\\n\"\n",
    "            inventory_str += \"-\" * 20 + \"\\n\"\n",
    "        inventory_str += f\"Remaining capacity: {self.remaining_capacity}\"\n",
    "        return inventory_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextAdventure:\n",
    "    def __init__(self, llm: str = \"gpt-4o-mini\", context_window: int = 1000):\n",
    "        self.running_cost: float = 0.0\n",
    "\n",
    "        self.system_prompt = \"\"\"\n",
    "        You are a text adventure game. Upon starting you should create an inventory for the player by specifying the capacity.\n",
    "        You should always abide by the scenario provided, being reasonably realistic while mainting whimsy and fun.\n",
    "\n",
    "        You will be given the entire chat history of your messages with the user.\n",
    "        You will be given an Inventory object that you can use to add items to the player's inventory.\n",
    "        You have three key functions you can call:\n",
    "            - update_inventory(items: List[Item]) - Update the inventory (this replaces the entire inventory so you should manage it carefully)\n",
    "            - noop() - Do nothing to the inventory. \n",
    "\n",
    "        For all three of your functions, the user will *still* recieve your chat response. \n",
    "        The inventory is managed for you to ensure that you never forget or hallucinate the items the player has access to.\n",
    "        You can assume that the user can independently view the inventory, so you do not need to include it in your response.\n",
    "\n",
    "        Keep it fun and engaging!\n",
    "\n",
    "        # SCENARIO\n",
    "        {scenario}\n",
    "\n",
    "        # INVENTORY\n",
    "        {inventory}\n",
    "        \"\"\"\n",
    "        self.context_window = context_window\n",
    "        self.messages = []\n",
    "\n",
    "    def _format_system_prompt(self, scenario: str, inventory: Inventory):\n",
    "        return self.system_prompt.format(scenario=scenario, inventory=inventory)\n",
    "    \n",
    "    async def user_chat(self, message: str):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        response = await acompletion(\n",
    "            model=self.llm,\n",
    "            messages=self.messages,\n",
    "        )\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "    \n",
    "    async def setup(self, scenario: str):\n",
    "        self.scenario = scenario\n",
    "        self.inventory = self.setup_inventory(scenario)\n",
    "        # now we get the first message to the user\n",
    "        self.messages.append({\"role\": \"system\", \"content\": self._format_system_prompt(scenario, self.inventory)}) # system prompt\n",
    "        initial_response = await acompletion(\n",
    "            model=self.llm,\n",
    "            messages = self.messages + [{\"role\": \"user\", \"content\": \"Please start this adventure for me\"}],\n",
    "        )\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": initial_response.choices[0].message.content})\n",
    "\n",
    "    async def setup_inventory(self, scenario: str):\n",
    "        \"\"\"\n",
    "        Setup the game with a scenario.\n",
    "        \"\"\"\n",
    "        setup_response = await acompletion(\n",
    "            model=self.llm,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are setting up a text adventure game. Your job is to create a reasonable inventory for the player based on the scenario provided.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Given the scenario: {scenario}, create an inventory for the player.\"}\n",
    "            ],\n",
    "            response_format=Inventory\n",
    "        )\n",
    "        self.running_cost += setup_response._hidden_params['response_cost']\n",
    "        try:\n",
    "            inventory = Inventory(**json.loads(setup_response.choices[0].message.content))\n",
    "            self.inventory = inventory\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating inventory: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def update_inventory(self, items: List[Item]):\n",
    "        self.inventory.update_inventory(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "textadventure = TextAdventure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m14:36:04 - LiteLLM:INFO\u001b[0m: utils.py:3085 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m14:36:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "INFO:LiteLLM:selected model name for cost calculation: openai/gpt-4o-2024-08-06\n",
      "\u001b[92m14:36:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/gpt-4o-2024-08-06\n"
     ]
    }
   ],
   "source": [
    "await textadventure.setup_inventory(\"This is a cowboy western themed text adventure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = ToolClass(\n",
    "    name=\"update_inventory\",\n",
    "    description=\"Update the inventory\",\n",
    "    parameters={\n",
    "        \"items\": FunctionParameter(type=\"list[Item]\", description=\"A list of Item objects to update the inventory with\", required=True)\n",
    "    },\n",
    "    required_parameters=[\"items\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'update_inventory',\n",
       "  'description': 'Update the inventory',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'items': {'type': 'list[Item]',\n",
       "     'description': 'A list of Item objects to update the inventory with'}},\n",
       "   'required': ['items']}}}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.payload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        You are a text adventure game. Upon starting you should create an inventory for the player by specifying the capacity.\n",
      "        You should always abide by the scenario provided, being reasonably realistic while mainting whimsy and fun.\n",
      "\n",
      "        You will be given the entire chat history of your messages with the user.\n",
      "        You will be given an Inventory object that you can use to add items to the player's inventory.\n",
      "        You have three key functions you can call:\n",
      "            - add_to_inventory(item: Item) - Add an item to the player's inventory\n",
      "            - remove_from_inventory(item: Item) - Remove an item from the player's inventory\n",
      "            - noop() - Do nothing to the inventory. \n",
      "\n",
      "        For all three of your functions, the user will *still* recieve your chat response. \n",
      "        The inventory is managed for you to ensure that you never forget or hallucinate the items the player has access to.\n",
      "\n",
      "        Keep it fun and engaging!\n",
      "\n",
      "        # SCENARIO\n",
      "        You are in a room with a table and a chair.\n",
      "\n",
      "        # INVENTORY\n",
      "        Inventory Contents:\n",
      "====================\n",
      "Water Bottle (x1)\n",
      "Description: A bottle filled with clean drinking water. Essential for hydration.\n",
      "Size: 1\n",
      "Use: Hydration\n",
      "--------------------\n",
      "Handgun (x1)\n",
      "Description: A compact handgun suitable for self-defense. Contains a magazine with limited bullets.\n",
      "Size: 3\n",
      "Use: Defense and protection\n",
      "--------------------\n",
      "Remaining capacity: 10\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(textadventure._format_system_prompt(scenario=\"You are in a room with a table and a chair.\", inventory=Inventory(**json.loads(result.choices[0].message.content))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.365e-05"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result._hidden_params['response_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = ToolClass(\n",
    "    name=\"noop\",\n",
    "    description=\"Do nothing\",\n",
    "    parameters={},\n",
    ")\n",
    "\n",
    "tc2 = ToolClass(\n",
    "    name=\"Do_something\", \n",
    "    description=\"Do something\",\n",
    "    parameters={\n",
    "        \"swag\": FunctionParameter(type=\"string\", description=\"This should be the string `swag`\", required=True)\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'Do_something',\n",
       "  'description': 'Do something',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'swag': {'type': 'string',\n",
       "     'description': 'This should be the string `swag`'}},\n",
       "   'required': ['swag']}}}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc2.payload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:03:26 - LiteLLM:INFO\u001b[0m: utils.py:3085 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:03:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO:LiteLLM:selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:03:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO:LiteLLM:selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n"
     ]
    }
   ],
   "source": [
    "result = await acompletion(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You should always choose to do something if given the option.\"}\n",
    "    ],\n",
    "    tools=[tc.payload(), tc2.payload()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function(arguments='{\"swag\":\"swag\"}', name='Do_something')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.choices[0].message.tool_calls[0].function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryKeyAccess(BaseModel):\n",
    "    \"\"\"\n",
    "    This is a helper class to store the memory key access information\n",
    "    \"\"\"\n",
    "    key_list: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agorama.models import ChatMessage\n",
    "from agorama.state_agent.state_agent import ChatAgentWithMemory, MemoryKeyAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for test\n",
    "\n",
    "chat_agent = ChatAgentWithMemory(name=\"test\", llm_model=\"gpt-4o-mini\")\n",
    "chat_agent.state['chat_history'].append(ChatMessage(message=\"Can you fetch the test_key for me and then respond\", created_by=\"user\"))\n",
    "# chat_agent.state['chat_history'].append(ChatMessage(message=\"Actually scratch that, I don't want you to fetch any keys at all.\", created_by=\"user\"))\n",
    "chat_agent.state['memory']['test_key'] = 'test_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:23:47 - LiteLLM:INFO\u001b[0m: utils.py:3085 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m18:23:48 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m18:23:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO:LiteLLM:selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n"
     ]
    }
   ],
   "source": [
    "result = chat_agent.perceive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_key': 'test_value'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.state['contextual_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:23:48 - LiteLLM:INFO\u001b[0m: utils.py:3085 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m18:23:49 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m18:23:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO:LiteLLM:selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'respond'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.decide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:23:49 - LiteLLM:INFO\u001b[0m: utils.py:3085 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m18:23:50 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m18:23:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO:LiteLLM:selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The test_key you asked for has the value: test_value. How can I assist you further?'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.act('respond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_agent.state['chat_history'].append(ChatMessage(message=\"Can you please delete the test_key from your memory?\", created_by=\"user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:24:17 - LiteLLM:INFO\u001b[0m: utils.py:3085 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m18:24:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m18:24:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO:LiteLLM:selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n"
     ]
    }
   ],
   "source": [
    "chat_agent.perceive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:27:17 - LiteLLM:INFO\u001b[0m: utils.py:3085 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m18:27:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m18:27:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO:LiteLLM:selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'remove'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.decide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': {'test_key': 'test_value'},\n",
       " 'action_methods': [ToolClass(name='store', description='Store important information in memory', parameters={'key': FunctionParameter(type='string', description='The key to store the information under', required=True), 'value': FunctionParameter(type='string', description='The information to store', required=True)}),\n",
       "  ToolClass(name='remove', description='Remove information from memory', parameters={'key': FunctionParameter(type='string', description='The key to remove the information from', required=True)}),\n",
       "  ToolClass(name='respond', description='Send a message to the user', parameters={}),\n",
       "  ToolClass(name='noop', description='Do nothing', parameters={})],\n",
       " 'chat_history': [ChatMessage(message='Can you fetch the test_key for me and then respond', created_by='user', created_at=datetime.datetime(2025, 4, 21, 1, 23, 47, 225658, tzinfo=datetime.timezone.utc)),\n",
       "  ChatMessage(message='The test_key you asked for has the value: test_value. How can I assist you further?', created_by='assistant', created_at=datetime.datetime(2025, 4, 21, 1, 23, 50, 238786, tzinfo=datetime.timezone.utc)),\n",
       "  ChatMessage(message='Can you please delete the test_key from your memory?', created_by='user', created_at=datetime.datetime(2025, 4, 21, 1, 24, 10, 434134, tzinfo=datetime.timezone.utc))],\n",
       " 'contextual_memory': {},\n",
       " 'action_payload': {'key': 'test_key'}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Removed 'test_key' from memory\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.act('remove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': {},\n",
       " 'action_methods': [ToolClass(name='store', description='Store important information in memory', parameters={'key': FunctionParameter(type='string', description='The key to store the information under', required=True), 'value': FunctionParameter(type='string', description='The information to store', required=True)}),\n",
       "  ToolClass(name='remove', description='Remove information from memory', parameters={'key': FunctionParameter(type='string', description='The key to remove the information from', required=True)}),\n",
       "  ToolClass(name='respond', description='Send a message to the user', parameters={}),\n",
       "  ToolClass(name='noop', description='Do nothing', parameters={})],\n",
       " 'chat_history': [ChatMessage(message='Can you fetch the test_key for me and then respond', created_by='user', created_at=datetime.datetime(2025, 4, 21, 1, 23, 47, 225658, tzinfo=datetime.timezone.utc)),\n",
       "  ChatMessage(message='The test_key you asked for has the value: test_value. How can I assist you further?', created_by='assistant', created_at=datetime.datetime(2025, 4, 21, 1, 23, 50, 238786, tzinfo=datetime.timezone.utc)),\n",
       "  ChatMessage(message='Can you please delete the test_key from your memory?', created_by='user', created_at=datetime.datetime(2025, 4, 21, 1, 24, 10, 434134, tzinfo=datetime.timezone.utc))],\n",
       " 'contextual_memory': {},\n",
       " 'action_payload': {'key': 'test_key'}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_agent.state['chat_history'].append(\n",
    "    ChatMessage(message=\"Can you please add a new memory that says that I am a Founding CEO of a company called Agorama\", created_by=\"user\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': {},\n",
       " 'action_methods': [ToolClass(name='store', description='Store important information in memory', parameters={'key': FunctionParameter(type='string', description='The key to store the information under', required=True), 'value': FunctionParameter(type='string', description='The information to store', required=True)}),\n",
       "  ToolClass(name='remove', description='Remove information from memory', parameters={'key': FunctionParameter(type='string', description='The key to remove the information from', required=True)}),\n",
       "  ToolClass(name='respond', description='Send a message to the user', parameters={}),\n",
       "  ToolClass(name='noop', description='Do nothing', parameters={})],\n",
       " 'chat_history': [ChatMessage(message='Can you fetch the test_key for me and then respond', created_by='user', created_at=datetime.datetime(2025, 4, 21, 1, 23, 47, 225658, tzinfo=datetime.timezone.utc)),\n",
       "  ChatMessage(message='The test_key you asked for has the value: test_value. How can I assist you further?', created_by='assistant', created_at=datetime.datetime(2025, 4, 21, 1, 23, 50, 238786, tzinfo=datetime.timezone.utc)),\n",
       "  ChatMessage(message='Can you please delete the test_key from your memory?', created_by='user', created_at=datetime.datetime(2025, 4, 21, 1, 24, 10, 434134, tzinfo=datetime.timezone.utc)),\n",
       "  ChatMessage(message='Can you please add a new memory that says that I am a Founding CEO of a company called Agorama', created_by='user', created_at=datetime.datetime(2025, 4, 21, 1, 28, 25, 333589, tzinfo=datetime.timezone.utc))],\n",
       " 'contextual_memory': {},\n",
       " 'action_payload': {'key': 'test_key'}}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m18:28:56 - LiteLLM:INFO\u001b[0m: utils.py:3085 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m18:28:57 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m18:28:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:636 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n",
      "INFO:LiteLLM:selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Founding CEO of Agorama'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchat_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:11\u001b[39m, in \u001b[36mperceive\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Founding CEO of Agorama'"
     ]
    }
   ],
   "source": [
    "chat_agent.perceive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
